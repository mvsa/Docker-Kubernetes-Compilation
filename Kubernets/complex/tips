docker-compose up
Original Files/folders deleted: travis.yml / docker-compose / dockerrun.aws / ./nginx
Folder k8s created to house all kubenets configs
created multi client config
created clusterIp service attached to multi clients
created multi server (express) config
created clusterIp service attached to multi server
created multi worker config file
created redis config file and its service
created postgres config file and its service
created claim config files and updated postgres deployment
defined env variable to multi worker(redishost/redisport)
defined env variable to multi server (pguser, pghost, pgdatabase, pgport, pgpassword)
--------------------------------------------------------------------------------------
This is a multi container application that originally was running on elastic beanstalk and will be converted to
kubernetes (1 config file for each object = total of 11)


---------------------------------------------------------------------------------------------------------------
**Persistent volume claim** 
PVC
Volume: share file system of a host machine with file system inside a container

if a pod crashes/restarts, and inside this pod we have a postgree container, the data stored inside this pod will be lost! (because the crashed pod will be deleted and a new one created)

by sharing the system file of a host to the containers it gives the pod the capacity to store some volume of data on the host that its running (good for databases)

only increasing the replicas (number) of a postgres deployment will not be the best strategy because we will end up with two pods accessing the same volume.
The problem is the pods is not aware of each other and it can cause problems.
To scale databases we needo to follow some additional configs besides just incrementing the number of replicas


Volume in generic container terminology = some type of mechanism that allows a container to access a filesystem outside itself

Volume in Kubernets = an OBJECT that allows a container to store data at the POD level {Persistent volume claim *** / Persistent volume ** / Volume*}

* Volume in kubernets will survive container restarts, but not pod restarts, not good for databases


** Persistent Volume: alowws container to store data outside the pod/deployment.
It can survive restarts and crashes

** Persistent Volume Claim: 
advertisiment of options of storage given to be used in the future, there are two options: 

1- Staticlly provisioned persistente volume = volumes available ahead of time, they have alread been created and can be used

2 - Dinamically provisioned persisten volume = volumes that are not yet been created but can be created on the fly when requested.

We will attach this PVC to the postegres deployment

in a dev enviroment the only option to storage available will be the harddrive of the device, and so we dont need to specify the source in the config file
In an cloud provider (prod) kubernets will automaticly set based on wich storage option you are using
but i can me manually set too (storageclassname)

known storage options: {
    Google cloud persistent disk / azure file / azure disk / aws block store
    kubernetes.io/docs/concepts/storage/storage-classes
}

pvc = is the advertisment of what can be get
pv = is the actual instance of storage that meets the requirements of the pvc


**ClusterIP Service**
Exposes a set of pods to other objects in the cluster
Allow that any other object inside our cluster to access the object that the clusterip is point out. Only internal
not to the outside world

In ex, if a deployment has a clusterIP atached to it, this deployment can be accessed by any other object inside the cluster. Whitou it they will become unreachable

**NodePort Service**
Exposes a container to the outside world (only good for dev purposes)

**Ingress Service**
Front door, traffic (outside world) will come to the ingress and then the deployments will be accessible
Exposes a set of services to the outside world


**Load Balance Service** (deprecated?)
Legacy way of getting network traffic into a cluster, only grants access to ONE set of pods
it will use your cloud provider (aws, google, etc) and will create a loadBalancer with their configuration or definition of what a load balance is



**Secrets**
Object Type that securely stores a piece of information in the cluster, such as
database password
to create a secret we use a imperative command,this way we dont have to write our secret in some config file.
This means that in a production enviroment we will have to manually set this config aswell.

- kubectl create secret generic <secrete_name> --from-literal key=value -
    ex kubectl create secret generic pgpassword --from-literal PGPASSWORD=pass123

generic = type Of secret {other types of types docker-registry / tls}
--from-literal = means that we are going to add the secret information into this command, as opposed to from a file

-------------------------------------------------------------------------------------
**COMMANDS**
kubectl apply -f k8s   =  apply all config files from one directory
kubectl logs <name of object>

kubectl get storageclass = return the list of available storage options
kubectl describe storageclass

kubectl create secret generic <secrete_name> --from-literal key=value
-------------------------------------------------------------------------------------------
TRIVIA:
Nginx server = routing inside application was replaced by ingress service

rather than putting a separate file for each one of the objects we can create a single file to group different objects config, just copy and paste on the end of each config followed by a --- at the final line (not doing this in this project)

When aplying config giles = cannot convert int64 to string
occours when in our config files we provided some env variable as integers:
ex: value:6579
to correct this, use single quotes on this values 
